{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import tqdm\n",
    "import argparse\n",
    "import tqdm\n",
    "from collections import defaultdict, Counter\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch import nn, cuda\n",
    "from torch.autograd import Variable \n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import CenterCrop\n",
    "\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, StepLR\n",
    "\n",
    "# from efficientnet_pytorch import EfficientNet\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.optim import Optimizer\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def mae(y_true, y_pred) :\n",
    "    y_true, y_pred = np.array(y_true.detach().numpy()), np.array(y_pred.detach().numpy())\n",
    "    y_true = y_true.reshape(1, -1)[0]\n",
    "    y_pred = y_pred.reshape(1, -1)[0]\n",
    "    over_threshold = y_true >= 0.1\n",
    "    return np.mean(np.abs(y_true[over_threshold] - y_pred[over_threshold]))\n",
    "\n",
    "def fscore(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true.detach().numpy()), np.array(y_pred.detach().numpy())\n",
    "    y_true = y_true.reshape(1, -1)[0]\n",
    "    y_pred = y_pred.reshape(1, -1)[0]\n",
    "    remove_NAs = y_true >= 0\n",
    "    y_true = np.where(y_true[remove_NAs] >= 0.1, 1, 0)\n",
    "    y_pred = np.where(y_pred[remove_NAs] >= 0.1, 1, 0)\n",
    "    return(f1_score(y_true, y_pred))\n",
    "\n",
    "def maeOverFscore(y_true, y_pred):\n",
    "    return mae(y_true, y_pred) / (fscore(y_true, y_pred) + 1e-07)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **File info**\n",
    "**ex. subset_010462_01**\n",
    "> **orbit 010462**\n",
    "\n",
    "> **subset 01**\n",
    "\n",
    "> **ortbit 별로 subset 개수는 다를 수 있고 연속적이지 않을 수도 있음**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>orbit</th>\n",
       "      <th>orbit_subset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../D_WEATHER//input/train/subset_010462_01.npy</td>\n",
       "      <td>10462</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../D_WEATHER//input/train/subset_010462_02.npy</td>\n",
       "      <td>10462</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../D_WEATHER//input/train/subset_010462_03.npy</td>\n",
       "      <td>10462</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../D_WEATHER//input/train/subset_010462_04.npy</td>\n",
       "      <td>10462</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../D_WEATHER//input/train/subset_010462_05.npy</td>\n",
       "      <td>10462</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             path  orbit  orbit_subset\n",
       "0  ../D_WEATHER//input/train/subset_010462_01.npy  10462             1\n",
       "1  ../D_WEATHER//input/train/subset_010462_02.npy  10462             2\n",
       "2  ../D_WEATHER//input/train/subset_010462_03.npy  10462             3\n",
       "3  ../D_WEATHER//input/train/subset_010462_04.npy  10462             4\n",
       "4  ../D_WEATHER//input/train/subset_010462_05.npy  10462             5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_df = pd.read_csv(\"../D_WEATHER//input/train_df.csv\")\n",
    "te_df = pd.read_csv(\"../D_WEATHER/input/test_df.csv\")\n",
    "tr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((61076, 3), (15269, 3))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = tr_df[:int(len(tr_df)*0.8)]\n",
    "valid_df = tr_df[int(len(tr_df)*0.8):]\n",
    "\n",
    "train_df.shape, valid_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Weather_Dataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        \n",
    "        self.image_list = []\n",
    "        self.label_list = []\n",
    "\n",
    "        for file in self.df['path']:\n",
    "            data = np.load(file)\n",
    "            image = data[:,:,:9] # use 14 channels except target\n",
    "            image = np.transpose(image, (2,0,1))\n",
    "            image = image.astype(np.float32)\n",
    "            self.image_list.append(image)\n",
    "            \n",
    "            label = data[:,:,-1].reshape(40,40,1)\n",
    "            label = np.transpose(label, (2,0,1))\n",
    "            self.label_list.append(label)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        image = self.image_list[idx]\n",
    "        label = self.label_list[idx]\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def worker_init(worker_id):\n",
    "#     np.random.seed(SEED)\n",
    "\n",
    "def build_dataloader(df, batch_size, shuffle=False):\n",
    "    dataset = Weather_Dataset(df)\n",
    "    dataloader = DataLoader(\n",
    "                            dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=shuffle,\n",
    "                            num_workers=0,\n",
    "#                             worker_init_fn=worker_init\n",
    "    )\n",
    "    return dataloader\n",
    "\n",
    "def build_te_dataloader(df, batch_size, shuffle=False):\n",
    "    dataset = Test_Dataset(df)\n",
    "    dataloader = DataLoader(\n",
    "                            dataset,\n",
    "                            batch_size=batch_size,\n",
    "                            shuffle=shuffle,\n",
    "                            num_workers=0,\n",
    "#                             worker_init_fn=worker_init\n",
    "                            )\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, bilinear=True):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels # \n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc = DoubleConv(n_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = Down(512, 1024 // factor)\n",
    "        self.up1 = Up(1024, 512, bilinear)\n",
    "        self.up2 = Up(512, 256, bilinear)\n",
    "        self.up3 = Up(256, 128, bilinear)\n",
    "        self.up4 = Up(128, 64 * factor, bilinear)\n",
    "        self.outc = OutConv(64, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            self.conv = DoubleConv(in_channels, out_channels // 2, in_channels // 2)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels , in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffY = torch.tensor([x2.size()[2] - x1.size()[2]])\n",
    "        diffX = torch.tensor([x2.size()[3] - x1.size()[3]])\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        # if you have padding issues, see\n",
    "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
    "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "batch_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = build_dataloader(tr_df, batch_size, shuffle=True)\n",
    "# valid_loader = build_dataloader(valid_df, batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enable gpu use\n"
     ]
    }
   ],
   "source": [
    "SEED = 42\n",
    "seed_everything(SEED)\n",
    "\n",
    "device = 'cuda:0'\n",
    "use_gpu = cuda.is_available()\n",
    "if use_gpu:\n",
    "    print(\"enable gpu use\")\n",
    "else:\n",
    "    print(\"enable cpu for debugging\")\n",
    "\n",
    "model = UNet(n_channels=9, n_classes=1, bilinear=False) # if bilinear = True -> non deterministic : not recommended\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 40, 40]           5,248\n",
      "       BatchNorm2d-2           [-1, 64, 40, 40]             128\n",
      "              ReLU-3           [-1, 64, 40, 40]               0\n",
      "            Conv2d-4           [-1, 64, 40, 40]          36,928\n",
      "       BatchNorm2d-5           [-1, 64, 40, 40]             128\n",
      "              ReLU-6           [-1, 64, 40, 40]               0\n",
      "        DoubleConv-7           [-1, 64, 40, 40]               0\n",
      "         MaxPool2d-8           [-1, 64, 20, 20]               0\n",
      "            Conv2d-9          [-1, 128, 20, 20]          73,856\n",
      "      BatchNorm2d-10          [-1, 128, 20, 20]             256\n",
      "             ReLU-11          [-1, 128, 20, 20]               0\n",
      "           Conv2d-12          [-1, 128, 20, 20]         147,584\n",
      "      BatchNorm2d-13          [-1, 128, 20, 20]             256\n",
      "             ReLU-14          [-1, 128, 20, 20]               0\n",
      "       DoubleConv-15          [-1, 128, 20, 20]               0\n",
      "             Down-16          [-1, 128, 20, 20]               0\n",
      "        MaxPool2d-17          [-1, 128, 10, 10]               0\n",
      "           Conv2d-18          [-1, 256, 10, 10]         295,168\n",
      "      BatchNorm2d-19          [-1, 256, 10, 10]             512\n",
      "             ReLU-20          [-1, 256, 10, 10]               0\n",
      "           Conv2d-21          [-1, 256, 10, 10]         590,080\n",
      "      BatchNorm2d-22          [-1, 256, 10, 10]             512\n",
      "             ReLU-23          [-1, 256, 10, 10]               0\n",
      "       DoubleConv-24          [-1, 256, 10, 10]               0\n",
      "             Down-25          [-1, 256, 10, 10]               0\n",
      "        MaxPool2d-26            [-1, 256, 5, 5]               0\n",
      "           Conv2d-27            [-1, 512, 5, 5]       1,180,160\n",
      "      BatchNorm2d-28            [-1, 512, 5, 5]           1,024\n",
      "             ReLU-29            [-1, 512, 5, 5]               0\n",
      "           Conv2d-30            [-1, 512, 5, 5]       2,359,808\n",
      "      BatchNorm2d-31            [-1, 512, 5, 5]           1,024\n",
      "             ReLU-32            [-1, 512, 5, 5]               0\n",
      "       DoubleConv-33            [-1, 512, 5, 5]               0\n",
      "             Down-34            [-1, 512, 5, 5]               0\n",
      "        MaxPool2d-35            [-1, 512, 2, 2]               0\n",
      "           Conv2d-36           [-1, 1024, 2, 2]       4,719,616\n",
      "      BatchNorm2d-37           [-1, 1024, 2, 2]           2,048\n",
      "             ReLU-38           [-1, 1024, 2, 2]               0\n",
      "           Conv2d-39           [-1, 1024, 2, 2]       9,438,208\n",
      "      BatchNorm2d-40           [-1, 1024, 2, 2]           2,048\n",
      "             ReLU-41           [-1, 1024, 2, 2]               0\n",
      "       DoubleConv-42           [-1, 1024, 2, 2]               0\n",
      "             Down-43           [-1, 1024, 2, 2]               0\n",
      "  ConvTranspose2d-44            [-1, 512, 4, 4]       2,097,664\n",
      "           Conv2d-45            [-1, 512, 5, 5]       4,719,104\n",
      "      BatchNorm2d-46            [-1, 512, 5, 5]           1,024\n",
      "             ReLU-47            [-1, 512, 5, 5]               0\n",
      "           Conv2d-48            [-1, 512, 5, 5]       2,359,808\n",
      "      BatchNorm2d-49            [-1, 512, 5, 5]           1,024\n",
      "             ReLU-50            [-1, 512, 5, 5]               0\n",
      "       DoubleConv-51            [-1, 512, 5, 5]               0\n",
      "               Up-52            [-1, 512, 5, 5]               0\n",
      "  ConvTranspose2d-53          [-1, 256, 10, 10]         524,544\n",
      "           Conv2d-54          [-1, 256, 10, 10]       1,179,904\n",
      "      BatchNorm2d-55          [-1, 256, 10, 10]             512\n",
      "             ReLU-56          [-1, 256, 10, 10]               0\n",
      "           Conv2d-57          [-1, 256, 10, 10]         590,080\n",
      "      BatchNorm2d-58          [-1, 256, 10, 10]             512\n",
      "             ReLU-59          [-1, 256, 10, 10]               0\n",
      "       DoubleConv-60          [-1, 256, 10, 10]               0\n",
      "               Up-61          [-1, 256, 10, 10]               0\n",
      "  ConvTranspose2d-62          [-1, 128, 20, 20]         131,200\n",
      "           Conv2d-63          [-1, 128, 20, 20]         295,040\n",
      "      BatchNorm2d-64          [-1, 128, 20, 20]             256\n",
      "             ReLU-65          [-1, 128, 20, 20]               0\n",
      "           Conv2d-66          [-1, 128, 20, 20]         147,584\n",
      "      BatchNorm2d-67          [-1, 128, 20, 20]             256\n",
      "             ReLU-68          [-1, 128, 20, 20]               0\n",
      "       DoubleConv-69          [-1, 128, 20, 20]               0\n",
      "               Up-70          [-1, 128, 20, 20]               0\n",
      "  ConvTranspose2d-71           [-1, 64, 40, 40]          32,832\n",
      "           Conv2d-72           [-1, 64, 40, 40]          73,792\n",
      "      BatchNorm2d-73           [-1, 64, 40, 40]             128\n",
      "             ReLU-74           [-1, 64, 40, 40]               0\n",
      "           Conv2d-75           [-1, 64, 40, 40]          36,928\n",
      "      BatchNorm2d-76           [-1, 64, 40, 40]             128\n",
      "             ReLU-77           [-1, 64, 40, 40]               0\n",
      "       DoubleConv-78           [-1, 64, 40, 40]               0\n",
      "               Up-79           [-1, 64, 40, 40]               0\n",
      "           Conv2d-80            [-1, 1, 40, 40]             577\n",
      "          OutConv-81            [-1, 1, 40, 40]               0\n",
      "================================================================\n",
      "Total params: 31,047,489\n",
      "Trainable params: 31,047,489\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.05\n",
      "Forward/backward pass size (MB): 24.72\n",
      "Params size (MB): 118.44\n",
      "Estimated Total Size (MB): 143.21\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "summary(model , input_size=(9,40,40))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training\n",
      "================ ༼ つ ◕_◕ ༽つ BEST epoch : 1, MOF : 5.994922273213095 \n",
      "E 1/200 tr_loss: 46.51867 tr_mae: 1.99645 tr_fs: 0.38995 tr_mof: 5.99492 lr: 0.001000 elapsed: 111\n",
      "================ ༼ つ ◕_◕ ༽つ BEST epoch : 2, MOF : 3.29276489989508 \n",
      "E 2/200 tr_loss: 44.40150 tr_mae: 1.81878 tr_fs: 0.55660 tr_mof: 3.29276 lr: 0.001000 elapsed: 112\n",
      "================ ༼ つ ◕_◕ ༽つ BEST epoch : 3, MOF : 2.9909716080601005 \n",
      "E 3/200 tr_loss: 44.39545 tr_mae: 1.76572 tr_fs: 0.59264 tr_mof: 2.99097 lr: 0.001000 elapsed: 111\n",
      "================ ༼ つ ◕_◕ ༽つ BEST epoch : 4, MOF : 2.8418853486134266 \n",
      "E 4/200 tr_loss: 44.39138 tr_mae: 1.73282 tr_fs: 0.61324 tr_mof: 2.84189 lr: 0.001000 elapsed: 110\n",
      "================ ༼ つ ◕_◕ ༽つ BEST epoch : 5, MOF : 2.725771531674237 \n",
      "E 5/200 tr_loss: 44.95878 tr_mae: 1.70860 tr_fs: 0.63049 tr_mof: 2.72577 lr: 0.001000 elapsed: 110\n",
      "================ ༼ つ ◕_◕ ༽つ BEST epoch : 6, MOF : 2.6184572964587183 \n",
      "E 6/200 tr_loss: 45.42279 tr_mae: 1.68703 tr_fs: 0.64493 tr_mof: 2.61846 lr: 0.001000 elapsed: 110\n",
      "================ ༼ つ ◕_◕ ༽つ BEST epoch : 7, MOF : 2.5473278361335328 \n",
      "E 7/200 tr_loss: 44.37979 tr_mae: 1.66674 tr_fs: 0.65433 tr_mof: 2.54733 lr: 0.001000 elapsed: 110\n",
      "================ ༼ つ ◕_◕ ༽つ BEST epoch : 8, MOF : 2.515939399977852 \n",
      "E 8/200 tr_loss: 44.37779 tr_mae: 1.65033 tr_fs: 0.65655 tr_mof: 2.51594 lr: 0.001000 elapsed: 110\n",
      "================ ༼ つ ◕_◕ ༽つ BEST epoch : 9, MOF : 2.466473720954491 \n",
      "E 9/200 tr_loss: 44.37756 tr_mae: 1.63040 tr_fs: 0.66121 tr_mof: 2.46647 lr: 0.001000 elapsed: 110\n",
      "================ ༼ つ ◕_◕ ༽つ BEST epoch : 10, MOF : 2.417645429079044 \n",
      "E 10/200 tr_loss: 44.37219 tr_mae: 1.61517 tr_fs: 0.66844 tr_mof: 2.41765 lr: 0.001000 elapsed: 111\n",
      "================ ༼ つ ◕_◕ ༽つ BEST epoch : 11, MOF : 2.3843037500735424 \n",
      "E 11/200 tr_loss: 44.37101 tr_mae: 1.60161 tr_fs: 0.67187 tr_mof: 2.38430 lr: 0.001000 elapsed: 110\n",
      "E 12/200 tr_loss: 44.37129 tr_mae: 1.60199 tr_fs: 0.67115 tr_mof: 2.38822 lr: 0.001000 elapsed: 109\n",
      "================ ༼ つ ◕_◕ ༽つ BEST epoch : 13, MOF : 2.3448949363272478 \n",
      "E 13/200 tr_loss: 44.36908 tr_mae: 1.58825 tr_fs: 0.67744 tr_mof: 2.34489 lr: 0.001000 elapsed: 110\n",
      "================ ༼ つ ◕_◕ ༽つ BEST epoch : 14, MOF : 2.335334305455409 \n",
      "E 14/200 tr_loss: 44.36783 tr_mae: 1.57941 tr_fs: 0.67650 tr_mof: 2.33533 lr: 0.001000 elapsed: 110\n",
      "================ ༼ つ ◕_◕ ༽つ BEST epoch : 15, MOF : 2.3008463105522967 \n",
      "E 15/200 tr_loss: 44.36629 tr_mae: 1.56911 tr_fs: 0.68205 tr_mof: 2.30085 lr: 0.001000 elapsed: 110\n",
      "================ ༼ つ ◕_◕ ༽つ BEST epoch : 16, MOF : 2.286164534414118 \n",
      "E 16/200 tr_loss: 44.36533 tr_mae: 1.56464 tr_fs: 0.68405 tr_mof: 2.28616 lr: 0.001000 elapsed: 111\n",
      "================ ༼ つ ◕_◕ ༽つ BEST epoch : 17, MOF : 2.2647785747442724 \n",
      "E 17/200 tr_loss: 44.36417 tr_mae: 1.55547 tr_fs: 0.68684 tr_mof: 2.26478 lr: 0.001000 elapsed: 111\n",
      "================ ༼ つ ◕_◕ ༽つ BEST epoch : 18, MOF : 2.2459499087745725 \n",
      "E 18/200 tr_loss: 44.36335 tr_mae: 1.54805 tr_fs: 0.68931 tr_mof: 2.24595 lr: 0.001000 elapsed: 110\n",
      "================ ༼ つ ◕_◕ ༽つ BEST epoch : 19, MOF : 2.228927108129577 \n",
      "E 19/200 tr_loss: 44.36267 tr_mae: 1.54047 tr_fs: 0.69124 tr_mof: 2.22893 lr: 0.001000 elapsed: 110\n",
      "================ ༼ つ ◕_◕ ༽つ BEST epoch : 20, MOF : 2.2198330537939657 \n",
      "E 20/200 tr_loss: 44.36202 tr_mae: 1.53400 tr_fs: 0.69088 tr_mof: 2.21983 lr: 0.001000 elapsed: 110\n",
      "E 21/200 tr_loss: 45.40223 tr_mae: 1.54253 tr_fs: 0.68720 tr_mof: 2.24771 lr: 0.001000 elapsed: 110\n",
      "================ ༼ つ ◕_◕ ༽つ BEST epoch : 22, MOF : 2.2034086122911494 \n",
      "E 22/200 tr_loss: 44.36144 tr_mae: 1.53189 tr_fs: 0.69526 tr_mof: 2.20341 lr: 0.001000 elapsed: 110\n",
      "================ ༼ つ ◕_◕ ༽つ BEST epoch : 23, MOF : 2.176207909244911 \n",
      "E 23/200 tr_loss: 44.35988 tr_mae: 1.51550 tr_fs: 0.69650 tr_mof: 2.17621 lr: 0.001000 elapsed: 110\n",
      "================ ༼ つ ◕_◕ ༽つ BEST epoch : 24, MOF : 2.1488022511994456 \n",
      "E 24/200 tr_loss: 44.35864 tr_mae: 1.50399 tr_fs: 0.69992 tr_mof: 2.14880 lr: 0.001000 elapsed: 110\n",
      "E 25/200 tr_loss: 45.39876 tr_mae: 1.50903 tr_fs: 0.69662 tr_mof: 2.16804 lr: 0.001000 elapsed: 109\n",
      "E 26/200 tr_loss: 45.39846 tr_mae: 1.51321 tr_fs: 0.69616 tr_mof: 2.17479 lr: 0.001000 elapsed: 109\n",
      "================ ༼ つ ◕_◕ ༽つ BEST epoch : 27, MOF : 2.133391937610873 \n",
      "E 27/200 tr_loss: 45.39685 tr_mae: 1.49549 tr_fs: 0.70107 tr_mof: 2.13339 lr: 0.001000 elapsed: 110\n",
      "================ ༼ つ ◕_◕ ༽つ BEST epoch : 28, MOF : 2.108737197463468 \n",
      "E 28/200 tr_loss: 45.39623 tr_mae: 1.48706 tr_fs: 0.70524 tr_mof: 2.10874 lr: 0.001000 elapsed: 110\n",
      "E 29/200 tr_loss: 44.35714 tr_mae: 1.48660 tr_fs: 0.70478 tr_mof: 2.10973 lr: 0.001000 elapsed: 109\n",
      "================ ༼ つ ◕_◕ ༽つ BEST epoch : 30, MOF : 2.097822377866431 \n",
      "E 30/200 tr_loss: 44.35679 tr_mae: 1.48232 tr_fs: 0.70700 tr_mof: 2.09782 lr: 0.001000 elapsed: 110\n",
      "================ ༼ つ ◕_◕ ༽つ BEST epoch : 31, MOF : 2.083436525890455 \n",
      "E 31/200 tr_loss: 44.35566 tr_mae: 1.47423 tr_fs: 0.70775 tr_mof: 2.08344 lr: 0.001000 elapsed: 110\n",
      "================ ༼ つ ◕_◕ ༽つ BEST epoch : 32, MOF : 2.0679527283342765 \n",
      "E 32/200 tr_loss: 44.35508 tr_mae: 1.46819 tr_fs: 0.71026 tr_mof: 2.06795 lr: 0.001000 elapsed: 110\n",
      "================ ༼ つ ◕_◕ ༽つ BEST epoch : 33, MOF : 2.064378397751676 \n",
      "E 33/200 tr_loss: 47.44210 tr_mae: 1.46517 tr_fs: 0.71004 tr_mof: 2.06438 lr: 0.001000 elapsed: 110\n",
      "================ ༼ つ ◕_◕ ༽つ BEST epoch : 34, MOF : 2.0532127673413965 \n",
      "E 34/200 tr_loss: 44.35472 tr_mae: 1.46355 tr_fs: 0.71293 tr_mof: 2.05321 lr: 0.001000 elapsed: 111\n",
      "================ ༼ つ ◕_◕ ༽つ BEST epoch : 35, MOF : 2.024467280749649 \n",
      "E 35/200 tr_loss: 44.35346 tr_mae: 1.44976 tr_fs: 0.71629 tr_mof: 2.02447 lr: 0.001000 elapsed: 110\n",
      "E 36/200 tr_loss: 44.35383 tr_mae: 1.45242 tr_fs: 0.71550 tr_mof: 2.03071 lr: 0.001000 elapsed: 109\n",
      "================ ༼ つ ◕_◕ ༽つ BEST epoch : 37, MOF : 2.0227835648099193 \n",
      "E 37/200 tr_loss: 45.39315 tr_mae: 1.45092 tr_fs: 0.71726 tr_mof: 2.02278 lr: 0.001000 elapsed: 110\n",
      "================ ༼ つ ◕_◕ ༽つ BEST epoch : 38, MOF : 2.0031543654062953 \n",
      "E 38/200 tr_loss: 44.35277 tr_mae: 1.44253 tr_fs: 0.72042 tr_mof: 2.00315 lr: 0.001000 elapsed: 110\n",
      "E 39/200 tr_loss: 44.35334 tr_mae: 1.44467 tr_fs: 0.71845 tr_mof: 2.01154 lr: 0.001000 elapsed: 109\n",
      "================ ༼ つ ◕_◕ ༽つ BEST epoch : 40, MOF : 1.9976015835072223 \n",
      "E 40/200 tr_loss: 44.35290 tr_mae: 1.44106 tr_fs: 0.72153 tr_mof: 1.99760 lr: 0.001000 elapsed: 110\n",
      "================ ༼ つ ◕_◕ ༽つ BEST epoch : 41, MOF : 1.9763006565277517 \n",
      "E 41/200 tr_loss: 44.92627 tr_mae: 1.42980 tr_fs: 0.72366 tr_mof: 1.97630 lr: 0.001000 elapsed: 111\n",
      "E 42/200 tr_loss: 44.35236 tr_mae: 1.43238 tr_fs: 0.72453 tr_mof: 1.97713 lr: 0.001000 elapsed: 110\n",
      "E 43/200 tr_loss: 45.39200 tr_mae: 1.43531 tr_fs: 0.72276 tr_mof: 1.98691 lr: 0.001000 elapsed: 109\n",
      "================ ༼ つ ◕_◕ ༽つ BEST epoch : 44, MOF : 1.953640813539967 \n",
      "E 44/200 tr_loss: 44.35153 tr_mae: 1.42364 tr_fs: 0.72880 tr_mof: 1.95364 lr: 0.001000 elapsed: 110\n",
      "================ ༼ つ ◕_◕ ༽つ BEST epoch : 45, MOF : 1.9444608344710175 \n",
      "E 45/200 tr_loss: 44.35120 tr_mae: 1.42003 tr_fs: 0.73017 tr_mof: 1.94446 lr: 0.001000 elapsed: 110\n",
      "================ ༼ つ ◕_◕ ༽つ BEST epoch : 46, MOF : 1.9297636295428533 \n",
      "E 46/200 tr_loss: 45.39015 tr_mae: 1.41146 tr_fs: 0.73145 tr_mof: 1.92976 lr: 0.001000 elapsed: 110\n",
      "================ ༼ つ ◕_◕ ༽つ BEST epoch : 47, MOF : 1.9215370675076675 \n",
      "E 47/200 tr_loss: 44.35065 tr_mae: 1.40986 tr_fs: 0.73372 tr_mof: 1.92154 lr: 0.001000 elapsed: 110\n",
      "================ ༼ つ ◕_◕ ༽つ BEST epoch : 48, MOF : 1.9147873293085944 \n",
      "E 48/200 tr_loss: 44.92209 tr_mae: 1.40686 tr_fs: 0.73489 tr_mof: 1.91479 lr: 0.001000 elapsed: 110\n",
      "E 49/200 tr_loss: 44.35074 tr_mae: 1.41091 tr_fs: 0.73548 tr_mof: 1.91853 lr: 0.001000 elapsed: 110\n",
      "================ ༼ つ ◕_◕ ༽つ BEST epoch : 50, MOF : 1.9136715209757653 \n",
      "E 50/200 tr_loss: 44.35053 tr_mae: 1.40626 tr_fs: 0.73483 tr_mof: 1.91367 lr: 0.001000 elapsed: 110\n",
      "================ ༼ つ ◕_◕ ༽つ BEST epoch : 51, MOF : 1.9006188198005451 \n",
      "E 51/200 tr_loss: 44.34979 tr_mae: 1.40138 tr_fs: 0.73738 tr_mof: 1.90062 lr: 0.001000 elapsed: 110\n",
      "================ ༼ つ ◕_◕ ༽つ BEST epoch : 52, MOF : 1.8840760990388608 \n",
      "E 52/200 tr_loss: 44.34948 tr_mae: 1.39351 tr_fs: 0.73961 tr_mof: 1.88408 lr: 0.001000 elapsed: 110\n",
      "E 53/200 tr_loss: 44.35003 tr_mae: 1.40145 tr_fs: 0.73825 tr_mof: 1.89860 lr: 0.001000 elapsed: 109\n",
      "================ ༼ つ ◕_◕ ༽つ BEST epoch : 54, MOF : 1.878770745182283 \n",
      "E 54/200 tr_loss: 46.42807 tr_mae: 1.39291 tr_fs: 0.74125 tr_mof: 1.87877 lr: 0.001000 elapsed: 110\n",
      "================ ༼ つ ◕_◕ ༽つ BEST epoch : 55, MOF : 1.8755337998370885 \n",
      "E 55/200 tr_loss: 44.47582 tr_mae: 1.39201 tr_fs: 0.74222 tr_mof: 1.87553 lr: 0.001000 elapsed: 110\n",
      "E 56/200 tr_loss: 46.42821 tr_mae: 1.39461 tr_fs: 0.74032 tr_mof: 1.88366 lr: 0.001000 elapsed: 109\n",
      "================ ༼ つ ◕_◕ ༽つ BEST epoch : 57, MOF : 1.8739160109099746 \n",
      "E 57/200 tr_loss: 44.34937 tr_mae: 1.39168 tr_fs: 0.74273 tr_mof: 1.87392 lr: 0.001000 elapsed: 110\n",
      "E 58/200 tr_loss: 44.34948 tr_mae: 1.39519 tr_fs: 0.74107 tr_mof: 1.88257 lr: 0.001000 elapsed: 110\n",
      "================ ༼ つ ◕_◕ ༽つ BEST epoch : 59, MOF : 1.8734222432181151 \n",
      "E 59/200 tr_loss: 44.34891 tr_mae: 1.39141 tr_fs: 0.74296 tr_mof: 1.87342 lr: 0.001000 elapsed: 110\n",
      "================ ༼ つ ◕_◕ ༽つ BEST epoch : 60, MOF : 1.8732207464816393 \n",
      "E 60/200 tr_loss: 45.38863 tr_mae: 1.39109 tr_fs: 0.74267 tr_mof: 1.87322 lr: 0.001000 elapsed: 110\n",
      "================ ༼ つ ◕_◕ ༽つ BEST epoch : 61, MOF : 1.8634774943935537 \n",
      "E 61/200 tr_loss: 44.34904 tr_mae: 1.38856 tr_fs: 0.74515 tr_mof: 1.86348 lr: 0.001000 elapsed: 110\n",
      "E 62/200 tr_loss: 44.35115 tr_mae: 1.41738 tr_fs: 0.72814 tr_mof: 1.94732 lr: 0.001000 elapsed: 110\n",
      "E 63/200 tr_loss: 44.34958 tr_mae: 1.39684 tr_fs: 0.74416 tr_mof: 1.87671 lr: 0.001000 elapsed: 109\n",
      "E 64/200 tr_loss: 45.38896 tr_mae: 1.39366 tr_fs: 0.74389 tr_mof: 1.87376 lr: 0.001000 elapsed: 109\n",
      "E 65/200 tr_loss: 44.34906 tr_mae: 1.39061 tr_fs: 0.74574 tr_mof: 1.86642 lr: 0.001000 elapsed: 109\n",
      "E 66/200 tr_loss: 45.38934 tr_mae: 1.40035 tr_fs: 0.73968 tr_mof: 1.89360 lr: 0.001000 elapsed: 109\n",
      "E 67/200 tr_loss: 46.42868 tr_mae: 1.38882 tr_fs: 0.74369 tr_mof: 1.87061 lr: 0.001000 elapsed: 109\n",
      "================ ༼ つ ◕_◕ ༽つ BEST epoch : 68, MOF : 1.8574262065335005 \n",
      "E 68/200 tr_loss: 45.38780 tr_mae: 1.38404 tr_fs: 0.74519 tr_mof: 1.85743 lr: 0.000500 elapsed: 110\n",
      "================ ༼ つ ◕_◕ ༽つ BEST epoch : 69, MOF : 1.8400470982518802 \n",
      "E 69/200 tr_loss: 44.34846 tr_mae: 1.37997 tr_fs: 0.74970 tr_mof: 1.84005 lr: 0.000500 elapsed: 110\n",
      "================ ༼ つ ◕_◕ ༽つ BEST epoch : 70, MOF : 1.8245199082624046 \n",
      "E 70/200 tr_loss: 44.34807 tr_mae: 1.37391 tr_fs: 0.75305 tr_mof: 1.82452 lr: 0.000500 elapsed: 110\n",
      "E 71/200 tr_loss: 44.34811 tr_mae: 1.37974 tr_fs: 0.74952 tr_mof: 1.84053 lr: 0.000500 elapsed: 109\n",
      "E 72/200 tr_loss: 44.34832 tr_mae: 1.37954 tr_fs: 0.75158 tr_mof: 1.83532 lr: 0.000500 elapsed: 109\n",
      "E 73/200 tr_loss: 45.38820 tr_mae: 1.38083 tr_fs: 0.75152 tr_mof: 1.83699 lr: 0.000500 elapsed: 109\n",
      "E 74/200 tr_loss: 44.34853 tr_mae: 1.37549 tr_fs: 0.75182 tr_mof: 1.82921 lr: 0.000500 elapsed: 109\n",
      "E 75/200 tr_loss: 44.34847 tr_mae: 1.37914 tr_fs: 0.75215 tr_mof: 1.83364 lr: 0.000500 elapsed: 109\n",
      "E 76/200 tr_loss: 45.29100 tr_mae: 1.37883 tr_fs: 0.75178 tr_mof: 1.83421 lr: 0.000500 elapsed: 109\n",
      "================ ༼ つ ◕_◕ ༽つ BEST epoch : 77, MOF : 1.8136779972157855 \n",
      "E 77/200 tr_loss: 44.34756 tr_mae: 1.36898 tr_fs: 0.75452 tr_mof: 1.81368 lr: 0.000250 elapsed: 110\n",
      "E 78/200 tr_loss: 44.34760 tr_mae: 1.37141 tr_fs: 0.75463 tr_mof: 1.81711 lr: 0.000250 elapsed: 109\n",
      "E 79/200 tr_loss: 44.34773 tr_mae: 1.37443 tr_fs: 0.75533 tr_mof: 1.81953 lr: 0.000250 elapsed: 109\n",
      "E 80/200 tr_loss: 45.38698 tr_mae: 1.37225 tr_fs: 0.75441 tr_mof: 1.81891 lr: 0.000250 elapsed: 109\n",
      "E 81/200 tr_loss: 44.34747 tr_mae: 1.37103 tr_fs: 0.75539 tr_mof: 1.81500 lr: 0.000250 elapsed: 109\n",
      "E 82/200 tr_loss: 44.34782 tr_mae: 1.37339 tr_fs: 0.75521 tr_mof: 1.81836 lr: 0.000250 elapsed: 109\n",
      "E 83/200 tr_loss: 44.34769 tr_mae: 1.37346 tr_fs: 0.75520 tr_mof: 1.81853 lr: 0.000250 elapsed: 109\n",
      "E 84/200 tr_loss: 44.34797 tr_mae: 1.37397 tr_fs: 0.75599 tr_mof: 1.81726 lr: 0.000125 elapsed: 109\n",
      "================ ༼ つ ◕_◕ ༽つ BEST epoch : 85, MOF : 1.804432008698084 \n",
      "E 85/200 tr_loss: 44.34723 tr_mae: 1.36623 tr_fs: 0.75708 tr_mof: 1.80443 lr: 0.000125 elapsed: 110\n",
      "E 86/200 tr_loss: 44.34773 tr_mae: 1.37275 tr_fs: 0.75609 tr_mof: 1.81560 lr: 0.000125 elapsed: 109\n",
      "E 87/200 tr_loss: 45.38673 tr_mae: 1.36948 tr_fs: 0.75754 tr_mof: 1.80776 lr: 0.000125 elapsed: 110\n",
      "E 88/200 tr_loss: 44.34721 tr_mae: 1.36864 tr_fs: 0.75676 tr_mof: 1.80898 lr: 0.000125 elapsed: 109\n",
      "================ ༼ つ ◕_◕ ༽つ BEST epoch : 89, MOF : 1.8027783144897207 \n",
      "E 89/200 tr_loss: 44.34715 tr_mae: 1.36512 tr_fs: 0.75722 tr_mof: 1.80278 lr: 0.000125 elapsed: 110\n",
      "E 90/200 tr_loss: 44.34746 tr_mae: 1.37078 tr_fs: 0.75639 tr_mof: 1.81205 lr: 0.000125 elapsed: 109\n",
      "E 91/200 tr_loss: 44.34839 tr_mae: 1.37112 tr_fs: 0.75735 tr_mof: 1.80959 lr: 0.000125 elapsed: 109\n",
      "E 92/200 tr_loss: 44.34731 tr_mae: 1.36824 tr_fs: 0.75742 tr_mof: 1.80622 lr: 0.000125 elapsed: 109\n",
      "E 93/200 tr_loss: 45.38651 tr_mae: 1.36659 tr_fs: 0.75704 tr_mof: 1.80468 lr: 0.000125 elapsed: 109\n",
      "E 94/200 tr_loss: 44.34755 tr_mae: 1.37004 tr_fs: 0.75719 tr_mof: 1.80967 lr: 0.000125 elapsed: 109\n",
      "E 95/200 tr_loss: 44.34724 tr_mae: 1.36715 tr_fs: 0.75718 tr_mof: 1.80557 lr: 0.000125 elapsed: 109\n",
      "================ ༼ つ ◕_◕ ༽つ BEST epoch : 96, MOF : 1.795533459452917 \n",
      "E 96/200 tr_loss: 44.34695 tr_mae: 1.36169 tr_fs: 0.75828 tr_mof: 1.79553 lr: 0.000063 elapsed: 110\n",
      "E 97/200 tr_loss: 44.34707 tr_mae: 1.36662 tr_fs: 0.75848 tr_mof: 1.80161 lr: 0.000063 elapsed: 109\n",
      "E 98/200 tr_loss: 44.34711 tr_mae: 1.36289 tr_fs: 0.75849 tr_mof: 1.79630 lr: 0.000063 elapsed: 109\n",
      "E 99/200 tr_loss: 44.34724 tr_mae: 1.36738 tr_fs: 0.75820 tr_mof: 1.80325 lr: 0.000063 elapsed: 109\n",
      "E 100/200 tr_loss: 44.34718 tr_mae: 1.36672 tr_fs: 0.75838 tr_mof: 1.80181 lr: 0.000063 elapsed: 110\n",
      "E 101/200 tr_loss: 45.19660 tr_mae: 1.36215 tr_fs: 0.75814 tr_mof: 1.79601 lr: 0.000063 elapsed: 109\n",
      "E 102/200 tr_loss: 44.34716 tr_mae: 1.36664 tr_fs: 0.75787 tr_mof: 1.80341 lr: 0.000063 elapsed: 109\n",
      "================ ༼ つ ◕_◕ ༽つ BEST epoch : 103, MOF : 1.7938254583417572 \n",
      "E 103/200 tr_loss: 45.38615 tr_mae: 1.36204 tr_fs: 0.75911 tr_mof: 1.79383 lr: 0.000031 elapsed: 111\n",
      "E 104/200 tr_loss: 45.38634 tr_mae: 1.36322 tr_fs: 0.75883 tr_mof: 1.79618 lr: 0.000031 elapsed: 109\n",
      "E 105/200 tr_loss: 45.47057 tr_mae: 1.36255 tr_fs: 0.75836 tr_mof: 1.79644 lr: 0.000031 elapsed: 109\n",
      "E 106/200 tr_loss: 44.34673 tr_mae: 1.36397 tr_fs: 0.75835 tr_mof: 1.79847 lr: 0.000031 elapsed: 109\n",
      "E 107/200 tr_loss: 44.34689 tr_mae: 1.36398 tr_fs: 0.75865 tr_mof: 1.79705 lr: 0.000031 elapsed: 109\n",
      "E 108/200 tr_loss: 44.34747 tr_mae: 1.36624 tr_fs: 0.75895 tr_mof: 1.79987 lr: 0.000031 elapsed: 109\n",
      "E 109/200 tr_loss: 44.34689 tr_mae: 1.36396 tr_fs: 0.75905 tr_mof: 1.79681 lr: 0.000031 elapsed: 109\n",
      "E 110/200 tr_loss: 45.38594 tr_mae: 1.36127 tr_fs: 0.75875 tr_mof: 1.79390 lr: 0.000016 elapsed: 109\n",
      "E 111/200 tr_loss: 45.38650 tr_mae: 1.36642 tr_fs: 0.75895 tr_mof: 1.80072 lr: 0.000016 elapsed: 109\n",
      "================ ༼ つ ◕_◕ ༽つ BEST epoch : 112, MOF : 1.7924701381576509 \n",
      "E 112/200 tr_loss: 44.34673 tr_mae: 1.36200 tr_fs: 0.75973 tr_mof: 1.79247 lr: 0.000016 elapsed: 110\n",
      "E 113/200 tr_loss: 44.34641 tr_mae: 1.36116 tr_fs: 0.75902 tr_mof: 1.79324 lr: 0.000016 elapsed: 109\n",
      "================ ༼ つ ◕_◕ ༽つ BEST epoch : 114, MOF : 1.7923287174890217 \n",
      "E 114/200 tr_loss: 44.34671 tr_mae: 1.36083 tr_fs: 0.75907 tr_mof: 1.79233 lr: 0.000016 elapsed: 110\n",
      "E 115/200 tr_loss: 44.34728 tr_mae: 1.36649 tr_fs: 0.75929 tr_mof: 1.79951 lr: 0.000016 elapsed: 109\n",
      "================ ༼ つ ◕_◕ ༽つ BEST epoch : 116, MOF : 1.789360943003733 \n",
      "E 116/200 tr_loss: 44.34655 tr_mae: 1.35969 tr_fs: 0.75979 tr_mof: 1.78936 lr: 0.000016 elapsed: 110\n",
      "E 117/200 tr_loss: 44.34701 tr_mae: 1.36395 tr_fs: 0.75935 tr_mof: 1.79639 lr: 0.000016 elapsed: 109\n",
      "E 118/200 tr_loss: 45.38650 tr_mae: 1.36445 tr_fs: 0.75998 tr_mof: 1.79515 lr: 0.000016 elapsed: 109\n",
      "================ ༼ つ ◕_◕ ༽つ BEST epoch : 119, MOF : 1.7886998068117654 \n",
      "E 119/200 tr_loss: 44.34660 tr_mae: 1.35955 tr_fs: 0.76014 tr_mof: 1.78870 lr: 0.000016 elapsed: 110\n",
      "E 120/200 tr_loss: 44.34673 tr_mae: 1.36332 tr_fs: 0.75916 tr_mof: 1.79548 lr: 0.000016 elapsed: 109\n",
      "E 121/200 tr_loss: 44.34700 tr_mae: 1.36518 tr_fs: 0.75957 tr_mof: 1.79746 lr: 0.000016 elapsed: 109\n",
      "E 122/200 tr_loss: 44.34669 tr_mae: 1.36238 tr_fs: 0.75931 tr_mof: 1.79394 lr: 0.000016 elapsed: 109\n",
      "E 123/200 tr_loss: 45.38602 tr_mae: 1.36392 tr_fs: 0.75924 tr_mof: 1.79642 lr: 0.000016 elapsed: 109\n",
      "E 124/200 tr_loss: 44.34688 tr_mae: 1.36359 tr_fs: 0.75968 tr_mof: 1.79458 lr: 0.000016 elapsed: 109\n",
      "E 125/200 tr_loss: 44.34655 tr_mae: 1.36043 tr_fs: 0.75898 tr_mof: 1.79227 lr: 0.000016 elapsed: 109\n",
      "E 126/200 tr_loss: 44.34653 tr_mae: 1.36101 tr_fs: 0.75899 tr_mof: 1.79311 lr: 0.000008 elapsed: 109\n",
      "E 127/200 tr_loss: 45.38596 tr_mae: 1.36118 tr_fs: 0.75928 tr_mof: 1.79234 lr: 0.000008 elapsed: 109\n",
      "E 128/200 tr_loss: 44.34684 tr_mae: 1.36200 tr_fs: 0.75938 tr_mof: 1.79340 lr: 0.000008 elapsed: 109\n",
      "E 129/200 tr_loss: 44.34664 tr_mae: 1.36225 tr_fs: 0.75958 tr_mof: 1.79350 lr: 0.000008 elapsed: 110\n",
      "E 130/200 tr_loss: 44.34651 tr_mae: 1.36008 tr_fs: 0.75812 tr_mof: 1.79405 lr: 0.000008 elapsed: 109\n",
      "E 131/200 tr_loss: 44.34675 tr_mae: 1.35992 tr_fs: 0.75971 tr_mof: 1.78991 lr: 0.000008 elapsed: 109\n",
      "E 132/200 tr_loss: 45.38622 tr_mae: 1.36688 tr_fs: 0.75951 tr_mof: 1.79994 lr: 0.000004 elapsed: 109\n",
      "E 133/200 tr_loss: 44.68129 tr_mae: 1.36050 tr_fs: 0.75963 tr_mof: 1.79057 lr: 0.000004 elapsed: 109\n",
      "E 134/200 tr_loss: 45.38601 tr_mae: 1.36123 tr_fs: 0.75961 tr_mof: 1.79200 lr: 0.000004 elapsed: 109\n",
      "E 135/200 tr_loss: 46.42615 tr_mae: 1.36744 tr_fs: 0.75970 tr_mof: 1.79966 lr: 0.000004 elapsed: 111\n",
      "E 136/200 tr_loss: 44.34658 tr_mae: 1.36086 tr_fs: 0.75963 tr_mof: 1.79133 lr: 0.000004 elapsed: 110\n",
      "E 137/200 tr_loss: 44.34651 tr_mae: 1.36037 tr_fs: 0.75953 tr_mof: 1.79097 lr: 0.000004 elapsed: 109\n",
      "E 138/200 tr_loss: 44.34644 tr_mae: 1.35946 tr_fs: 0.75922 tr_mof: 1.79021 lr: 0.000002 elapsed: 109\n",
      "E 139/200 tr_loss: 44.34680 tr_mae: 1.36346 tr_fs: 0.75966 tr_mof: 1.79466 lr: 0.000002 elapsed: 109\n",
      "E 140/200 tr_loss: 44.34726 tr_mae: 1.36461 tr_fs: 0.75981 tr_mof: 1.79519 lr: 0.000002 elapsed: 109\n",
      "E 141/200 tr_loss: 44.34684 tr_mae: 1.36186 tr_fs: 0.75925 tr_mof: 1.79341 lr: 0.000002 elapsed: 109\n",
      "E 142/200 tr_loss: 45.38635 tr_mae: 1.36198 tr_fs: 0.76009 tr_mof: 1.79136 lr: 0.000002 elapsed: 109\n",
      "E 143/200 tr_loss: 45.38614 tr_mae: 1.35944 tr_fs: 0.75963 tr_mof: 1.78976 lr: 0.000002 elapsed: 109\n",
      "E 144/200 tr_loss: 44.34645 tr_mae: 1.36032 tr_fs: 0.76013 tr_mof: 1.79007 lr: 0.000001 elapsed: 110\n",
      "E 145/200 tr_loss: 44.34666 tr_mae: 1.35961 tr_fs: 0.75947 tr_mof: 1.78988 lr: 0.000001 elapsed: 109\n",
      "E 146/200 tr_loss: 44.34645 tr_mae: 1.35941 tr_fs: 0.75722 tr_mof: 1.79832 lr: 0.000001 elapsed: 109\n",
      "E 147/200 tr_loss: 44.34663 tr_mae: 1.35820 tr_fs: 0.75725 tr_mof: 1.79379 lr: 0.000001 elapsed: 109\n",
      "E 148/200 tr_loss: 44.34686 tr_mae: 1.36224 tr_fs: 0.75961 tr_mof: 1.79327 lr: 0.000001 elapsed: 109\n",
      "E 149/200 tr_loss: 45.38629 tr_mae: 1.36076 tr_fs: 0.75970 tr_mof: 1.79080 lr: 0.000001 elapsed: 109\n",
      "E 150/200 tr_loss: 44.34660 tr_mae: 1.36046 tr_fs: 0.75926 tr_mof: 1.79171 lr: 0.000000 elapsed: 109\n",
      "E 151/200 tr_loss: 44.34710 tr_mae: 1.36350 tr_fs: 0.75995 tr_mof: 1.79349 lr: 0.000000 elapsed: 109\n",
      "E 152/200 tr_loss: 44.34662 tr_mae: 1.36175 tr_fs: 0.75996 tr_mof: 1.79199 lr: 0.000000 elapsed: 109\n",
      "E 153/200 tr_loss: 44.34724 tr_mae: 1.36283 tr_fs: 0.75899 tr_mof: 1.79529 lr: 0.000000 elapsed: 109\n",
      "E 154/200 tr_loss: 44.34659 tr_mae: 1.36204 tr_fs: 0.75919 tr_mof: 1.79383 lr: 0.000000 elapsed: 109\n",
      "E 155/200 tr_loss: 44.34685 tr_mae: 1.36278 tr_fs: 0.75939 tr_mof: 1.79436 lr: 0.000000 elapsed: 109\n",
      "================ ༼ つ ◕_◕ ༽つ BEST epoch : 156, MOF : 1.7886308141039047 \n",
      "E 156/200 tr_loss: 45.38595 tr_mae: 1.35963 tr_fs: 0.76002 tr_mof: 1.78863 lr: 0.000000 elapsed: 110\n",
      "E 157/200 tr_loss: 44.34664 tr_mae: 1.36170 tr_fs: 0.75943 tr_mof: 1.79306 lr: 0.000000 elapsed: 109\n",
      "E 158/200 tr_loss: 44.34662 tr_mae: 1.36317 tr_fs: 0.75988 tr_mof: 1.79392 lr: 0.000000 elapsed: 109\n",
      "E 159/200 tr_loss: 45.38591 tr_mae: 1.36035 tr_fs: 0.75868 tr_mof: 1.79275 lr: 0.000000 elapsed: 109\n",
      "E 160/200 tr_loss: 44.34680 tr_mae: 1.35967 tr_fs: 0.75993 tr_mof: 1.78911 lr: 0.000000 elapsed: 109\n",
      "E 161/200 tr_loss: 44.34657 tr_mae: 1.36004 tr_fs: 0.75909 tr_mof: 1.79148 lr: 0.000000 elapsed: 109\n",
      "E 162/200 tr_loss: 45.38607 tr_mae: 1.36216 tr_fs: 0.75956 tr_mof: 1.79310 lr: 0.000000 elapsed: 109\n",
      "E 163/200 tr_loss: 44.34682 tr_mae: 1.36092 tr_fs: 0.75989 tr_mof: 1.79051 lr: 0.000000 elapsed: 110\n",
      "E 164/200 tr_loss: 44.34668 tr_mae: 1.36013 tr_fs: 0.75939 tr_mof: 1.79083 lr: 0.000000 elapsed: 109\n",
      "E 165/200 tr_loss: 44.34659 tr_mae: 1.36230 tr_fs: 0.76026 tr_mof: 1.79198 lr: 0.000000 elapsed: 109\n",
      "E 166/200 tr_loss: 44.34736 tr_mae: 1.37053 tr_fs: 0.75980 tr_mof: 1.80313 lr: 0.000000 elapsed: 109\n",
      "E 167/200 tr_loss: 44.34704 tr_mae: 1.36115 tr_fs: 0.75967 tr_mof: 1.79182 lr: 0.000000 elapsed: 109\n",
      "E 168/200 tr_loss: 44.34697 tr_mae: 1.36532 tr_fs: 0.75969 tr_mof: 1.79741 lr: 0.000000 elapsed: 110\n",
      "E 169/200 tr_loss: 44.34714 tr_mae: 1.36226 tr_fs: 0.75979 tr_mof: 1.79240 lr: 0.000000 elapsed: 109\n",
      "E 170/200 tr_loss: 44.86381 tr_mae: 1.36154 tr_fs: 0.75958 tr_mof: 1.79261 lr: 0.000000 elapsed: 109\n",
      "E 171/200 tr_loss: 44.34654 tr_mae: 1.36112 tr_fs: 0.75893 tr_mof: 1.79344 lr: 0.000000 elapsed: 109\n",
      "================ ༼ つ ◕_◕ ༽つ BEST epoch : 172, MOF : 1.7877797608319428 \n",
      "E 172/200 tr_loss: 45.38596 tr_mae: 1.35892 tr_fs: 0.76005 tr_mof: 1.78778 lr: 0.000000 elapsed: 110\n",
      "E 173/200 tr_loss: 44.34660 tr_mae: 1.35982 tr_fs: 0.75951 tr_mof: 1.78995 lr: 0.000000 elapsed: 109\n",
      "E 174/200 tr_loss: 45.39313 tr_mae: 1.35974 tr_fs: 0.75949 tr_mof: 1.78990 lr: 0.000000 elapsed: 109\n",
      "E 175/200 tr_loss: 44.34675 tr_mae: 1.35940 tr_fs: 0.75977 tr_mof: 1.78890 lr: 0.000000 elapsed: 109\n",
      "E 176/200 tr_loss: 44.34664 tr_mae: 1.35975 tr_fs: 0.75985 tr_mof: 1.78900 lr: 0.000000 elapsed: 109\n",
      "E 177/200 tr_loss: 44.99080 tr_mae: 1.36249 tr_fs: 0.75942 tr_mof: 1.79374 lr: 0.000000 elapsed: 109\n",
      "E 178/200 tr_loss: 44.34733 tr_mae: 1.36492 tr_fs: 0.75978 tr_mof: 1.79678 lr: 0.000000 elapsed: 109\n",
      "E 179/200 tr_loss: 45.38697 tr_mae: 1.37486 tr_fs: 0.75975 tr_mof: 1.80918 lr: 0.000000 elapsed: 110\n",
      "E 180/200 tr_loss: 44.34663 tr_mae: 1.35975 tr_fs: 0.75980 tr_mof: 1.78958 lr: 0.000000 elapsed: 109\n",
      "E 181/200 tr_loss: 44.34648 tr_mae: 1.35888 tr_fs: 0.75947 tr_mof: 1.78934 lr: 0.000000 elapsed: 110\n",
      "E 182/200 tr_loss: 45.18362 tr_mae: 1.36151 tr_fs: 0.75984 tr_mof: 1.79156 lr: 0.000000 elapsed: 109\n",
      "E 183/200 tr_loss: 45.38614 tr_mae: 1.36055 tr_fs: 0.75948 tr_mof: 1.79111 lr: 0.000000 elapsed: 109\n",
      "E 184/200 tr_loss: 44.34656 tr_mae: 1.35974 tr_fs: 0.75981 tr_mof: 1.78919 lr: 0.000000 elapsed: 109\n",
      "E 185/200 tr_loss: 44.34776 tr_mae: 1.36975 tr_fs: 0.75992 tr_mof: 1.80191 lr: 0.000000 elapsed: 110\n",
      "E 186/200 tr_loss: 44.80155 tr_mae: 1.36240 tr_fs: 0.75990 tr_mof: 1.79291 lr: 0.000000 elapsed: 109\n",
      "E 187/200 tr_loss: 44.34727 tr_mae: 1.36477 tr_fs: 0.76006 tr_mof: 1.79511 lr: 0.000000 elapsed: 109\n",
      "E 188/200 tr_loss: 45.38619 tr_mae: 1.36079 tr_fs: 0.75946 tr_mof: 1.79175 lr: 0.000000 elapsed: 109\n",
      "E 189/200 tr_loss: 45.38592 tr_mae: 1.35974 tr_fs: 0.75924 tr_mof: 1.79044 lr: 0.000000 elapsed: 109\n",
      "E 190/200 tr_loss: 44.34667 tr_mae: 1.36173 tr_fs: 0.75959 tr_mof: 1.79255 lr: 0.000000 elapsed: 109\n",
      "E 191/200 tr_loss: 44.34654 tr_mae: 1.36023 tr_fs: 0.75881 tr_mof: 1.79269 lr: 0.000000 elapsed: 109\n",
      "E 192/200 tr_loss: 44.34670 tr_mae: 1.36062 tr_fs: 0.75953 tr_mof: 1.79083 lr: 0.000000 elapsed: 109\n",
      "E 193/200 tr_loss: 44.34674 tr_mae: 1.36227 tr_fs: 0.75988 tr_mof: 1.79274 lr: 0.000000 elapsed: 109\n",
      "E 194/200 tr_loss: 44.99040 tr_mae: 1.35991 tr_fs: 0.75974 tr_mof: 1.78955 lr: 0.000000 elapsed: 109\n",
      "E 195/200 tr_loss: 45.38626 tr_mae: 1.36053 tr_fs: 0.75972 tr_mof: 1.79052 lr: 0.000000 elapsed: 109\n",
      "E 196/200 tr_loss: 44.34660 tr_mae: 1.36097 tr_fs: 0.75983 tr_mof: 1.79138 lr: 0.000000 elapsed: 109\n",
      "E 197/200 tr_loss: 44.70293 tr_mae: 1.36406 tr_fs: 0.75973 tr_mof: 1.79475 lr: 0.000000 elapsed: 109\n",
      "E 198/200 tr_loss: 44.34706 tr_mae: 1.36346 tr_fs: 0.75985 tr_mof: 1.79450 lr: 0.000000 elapsed: 109\n",
      "E 199/200 tr_loss: 44.34677 tr_mae: 1.36051 tr_fs: 0.75979 tr_mof: 1.79038 lr: 0.000000 elapsed: 109\n",
      "E 200/200 tr_loss: 44.34666 tr_mae: 1.35955 tr_fs: 0.75951 tr_mof: 1.78942 lr: 0.000000 elapsed: 109\n"
     ]
    }
   ],
   "source": [
    "# optimizer = optim.Adam(model.parameters(), lr, weight_decay=0.00025)\n",
    "# optimizer = AdamW(model.parameters(), 2.5e-4, weight_decay=0.000025)\n",
    "optimizer = optim.SGD(model.parameters(), lr, momentum=0.9, weight_decay=0.025)\n",
    "\n",
    "###### SCHEDULER #######\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5)\n",
    "\n",
    "#eta_min = 0.00001\n",
    "#T_max = 10\n",
    "#T_mult = 1\n",
    "#restart_decay = 0.97\n",
    "#scheduler = CosineAnnealingWithRestartsLR(optimizer, T_max=T_max, eta_min=eta_min, T_mult=T_mult, restart_decay=restart_decay)\n",
    "\n",
    "#scheduler = StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss() \n",
    "criterion = nn.L1Loss()\n",
    "\n",
    "def to_numpy(t):\n",
    "    return t.cpu().detach().numpy()\n",
    "\n",
    "best_mae_score = 999\n",
    "best_f_score = 999\n",
    "best_mof_score = 999\n",
    "grad_clip_step = 100\n",
    "grad_clip = 100\n",
    "step = 0\n",
    "# accumulation_step = 2\n",
    "EPOCH = 200\n",
    "\n",
    "model_fname = '../D_WEATHER/weight/unet_ch9_shuffle_trainall_sgd.pt'\n",
    "# log file\n",
    "log_df = pd.DataFrame(columns=['epoch_idx', 'train_loss', 'train_mae', 'train_fs', 'train_mof'])\n",
    "\n",
    "print(\"start training\")\n",
    "\n",
    "for epoch_idx in range(1, EPOCH + 1):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss = 0\n",
    "    train_mae = 0\n",
    "    train_fs = 0\n",
    "    train_mof = 0 \n",
    "#     train_total_correct = 0\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    for batch_idx, (image, labels) in enumerate(train_loader):\n",
    "        if use_gpu:\n",
    "            image = image.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "        output = model(image)\n",
    "        loss = criterion(output, labels)\n",
    "        mae_score = mae(labels.cpu(), output.cpu())\n",
    "        f_score = fscore(labels.cpu(), output.cpu())\n",
    "        mof_score = maeOverFscore(labels.cpu(), output.cpu())\n",
    "\n",
    "        # gradient explosion prevention\n",
    "        if step > grad_clip_step:\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "\n",
    "        step += 1\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        train_loss += loss.item() / len(train_loader)\n",
    "        train_mae += mae_score.item() / len(train_loader)\n",
    "        train_fs += f_score.item() / len(train_loader)\n",
    "        train_mof += mof_score.item() / len(train_loader)\n",
    "\n",
    "    # checkpoint\n",
    "    if train_mof < best_mof_score:\n",
    "        best_mof_score = train_mof\n",
    "#         print(\"Improved !! \")\n",
    "        torch.save(model.state_dict(), model_fname)\n",
    "        print(\"================ ༼ つ ◕_◕ ༽つ BEST epoch : {}, MOF : {} \".format(epoch_idx, best_mof_score))\n",
    "        #file_save_name = 'best_acc' + '_' + str(num_fold)\n",
    "        #print(file_save_name)\n",
    "#     else:\n",
    "#         print(\"val acc has not improved\")\n",
    "    elapsed = time.time() - start_time\n",
    "    lr = [_['lr'] for _ in optimizer.param_groups]\n",
    "\n",
    "    #if args.scheduler == 'plateau':\n",
    "    scheduler.step(train_mof)\n",
    "    \n",
    "    print(\"E {}/{} tr_loss: {:.5f} tr_mae: {:.5f} tr_fs: {:.5f} tr_mof: {:.5f} lr: {:.6f} elapsed: {:.0f}\".format(\n",
    "           epoch_idx, EPOCH, train_loss, train_mae, train_fs, train_mof, lr[0], elapsed))\n",
    "            #epoch_idx, args.epochs, train_loss, valid_loss, val_acc, lr[0], elapsed\n",
    "    # log file element\n",
    "#     log = []\n",
    "    log_data = [epoch_idx, train_loss, train_mae, train_fs, train_mof]\n",
    "#     log.append(log_data)\n",
    "    log_df.loc[epoch_idx] = log_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_df.to_csv(\"../D_WEATHER/log/unet_ch9_shuffle_trainall_sgd.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Test_Dataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        \n",
    "        self.image_list = []\n",
    "#         self.label_list = []\n",
    "\n",
    "        for file in self.df['path']:\n",
    "            data = np.load(file)\n",
    "#             image = data[:,:,:]\n",
    "            image = data[:,:,:9]#.reshape(40,40,-1)\n",
    "            image = np.transpose(image, (2,0,1))\n",
    "            image = image.astype(np.float32)\n",
    "            self.image_list.append(image)\n",
    "            \n",
    "#             label = data[:,:,-1].reshape(-1)\n",
    "#             self.label_list.append(label)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        image = self.image_list[idx]\n",
    "#         label = self.label_list[idx]\n",
    "        \n",
    "        return image#, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = build_te_dataloader(te_df, batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2416, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loader.dataset.df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 40, 40)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 40, 40)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loader.dataset[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict values check :  [ 1.42045435e-04 -1.66748092e-03 -3.56543064e-03 ...  2.98402647e-05\n",
      "  8.95622907e-06 -2.74365830e-05]\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(model_fname))\n",
    "model.eval()\n",
    "predictions = np.zeros((len(test_loader.dataset), 1600))\n",
    "with torch.no_grad():\n",
    "    for i, image in enumerate(test_loader):\n",
    "        image = image.to(device)\n",
    "        output = model(image)\n",
    "        \n",
    "        predictions[i*batch_size: (i+1)*batch_size] = output.detach().cpu().numpy().reshape(-1, 1600)\n",
    "print(\"predict values check : \",predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2416, 1600)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.42045435e-04, -1.66748092e-03, -3.56543064e-03, ...,\n",
       "        2.98402647e-05,  8.95622907e-06, -2.74365830e-05])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv(\"../D_WEATHER/input/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>px_1</th>\n",
       "      <th>px_2</th>\n",
       "      <th>px_3</th>\n",
       "      <th>px_4</th>\n",
       "      <th>px_5</th>\n",
       "      <th>px_6</th>\n",
       "      <th>px_7</th>\n",
       "      <th>px_8</th>\n",
       "      <th>px_9</th>\n",
       "      <th>...</th>\n",
       "      <th>px_1591</th>\n",
       "      <th>px_1592</th>\n",
       "      <th>px_1593</th>\n",
       "      <th>px_1594</th>\n",
       "      <th>px_1595</th>\n",
       "      <th>px_1596</th>\n",
       "      <th>px_1597</th>\n",
       "      <th>px_1598</th>\n",
       "      <th>px_1599</th>\n",
       "      <th>px_1600</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>029858_01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>029858_02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>029858_03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>029858_05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>029858_07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1601 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  px_1  px_2  px_3  px_4  px_5  px_6  px_7  px_8  px_9  ...  \\\n",
       "0  029858_01   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "1  029858_02   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "2  029858_03   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "3  029858_05   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "4  029858_07   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   \n",
       "\n",
       "   px_1591  px_1592  px_1593  px_1594  px_1595  px_1596  px_1597  px_1598  \\\n",
       "0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "1      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "2      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "3      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "4      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
       "\n",
       "   px_1599  px_1600  \n",
       "0      0.0      0.0  \n",
       "1      0.0      0.0  \n",
       "2      0.0      0.0  \n",
       "3      0.0      0.0  \n",
       "4      0.0      0.0  \n",
       "\n",
       "[5 rows x 1601 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.iloc[:,1:] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>px_1</th>\n",
       "      <th>px_2</th>\n",
       "      <th>px_3</th>\n",
       "      <th>px_4</th>\n",
       "      <th>px_5</th>\n",
       "      <th>px_6</th>\n",
       "      <th>px_7</th>\n",
       "      <th>px_8</th>\n",
       "      <th>px_9</th>\n",
       "      <th>...</th>\n",
       "      <th>px_1591</th>\n",
       "      <th>px_1592</th>\n",
       "      <th>px_1593</th>\n",
       "      <th>px_1594</th>\n",
       "      <th>px_1595</th>\n",
       "      <th>px_1596</th>\n",
       "      <th>px_1597</th>\n",
       "      <th>px_1598</th>\n",
       "      <th>px_1599</th>\n",
       "      <th>px_1600</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>029858_01</td>\n",
       "      <td>1.420454e-04</td>\n",
       "      <td>-1.667481e-03</td>\n",
       "      <td>-3.565431e-03</td>\n",
       "      <td>-1.482815e-03</td>\n",
       "      <td>2.971598e-03</td>\n",
       "      <td>1.805135e-02</td>\n",
       "      <td>2.083110e-02</td>\n",
       "      <td>0.012910</td>\n",
       "      <td>1.236481e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>-9.692004e-07</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>-0.000027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>029858_02</td>\n",
       "      <td>-6.313867e-07</td>\n",
       "      <td>3.748894e-06</td>\n",
       "      <td>-2.570984e-06</td>\n",
       "      <td>-2.502276e-06</td>\n",
       "      <td>-1.541049e-07</td>\n",
       "      <td>1.230757e-06</td>\n",
       "      <td>-3.127893e-07</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-1.131683e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>-2.549684e-06</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>-0.000029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>029858_03</td>\n",
       "      <td>2.840601e-06</td>\n",
       "      <td>4.038839e-06</td>\n",
       "      <td>-3.212639e-05</td>\n",
       "      <td>1.005665e-03</td>\n",
       "      <td>1.169641e-05</td>\n",
       "      <td>-1.232316e-03</td>\n",
       "      <td>-1.662385e-04</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>-2.796610e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-4.840686e-06</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>-0.000044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>029858_05</td>\n",
       "      <td>3.829724e-06</td>\n",
       "      <td>6.457018e-06</td>\n",
       "      <td>-1.508675e-07</td>\n",
       "      <td>2.777665e-08</td>\n",
       "      <td>3.525572e-06</td>\n",
       "      <td>4.301689e-06</td>\n",
       "      <td>6.308465e-06</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>3.379578e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-3.182040e-06</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>-0.000028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>029858_07</td>\n",
       "      <td>-2.082747e-06</td>\n",
       "      <td>-6.772109e-08</td>\n",
       "      <td>-5.581309e-06</td>\n",
       "      <td>2.675309e-06</td>\n",
       "      <td>9.427983e-07</td>\n",
       "      <td>3.519585e-07</td>\n",
       "      <td>-9.359679e-07</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-1.133617e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>1.691117</td>\n",
       "      <td>2.034608</td>\n",
       "      <td>1.726876</td>\n",
       "      <td>1.293826</td>\n",
       "      <td>1.495271</td>\n",
       "      <td>2.457459e+00</td>\n",
       "      <td>3.490596</td>\n",
       "      <td>3.771606</td>\n",
       "      <td>3.020589</td>\n",
       "      <td>1.592311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1601 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id          px_1          px_2          px_3          px_4  \\\n",
       "0  029858_01  1.420454e-04 -1.667481e-03 -3.565431e-03 -1.482815e-03   \n",
       "1  029858_02 -6.313867e-07  3.748894e-06 -2.570984e-06 -2.502276e-06   \n",
       "2  029858_03  2.840601e-06  4.038839e-06 -3.212639e-05  1.005665e-03   \n",
       "3  029858_05  3.829724e-06  6.457018e-06 -1.508675e-07  2.777665e-08   \n",
       "4  029858_07 -2.082747e-06 -6.772109e-08 -5.581309e-06  2.675309e-06   \n",
       "\n",
       "           px_5          px_6          px_7      px_8          px_9  ...  \\\n",
       "0  2.971598e-03  1.805135e-02  2.083110e-02  0.012910  1.236481e-03  ...   \n",
       "1 -1.541049e-07  1.230757e-06 -3.127893e-07 -0.000002 -1.131683e-07  ...   \n",
       "2  1.169641e-05 -1.232316e-03 -1.662385e-04  0.000014 -2.796610e-06  ...   \n",
       "3  3.525572e-06  4.301689e-06  6.308465e-06  0.000005  3.379578e-06  ...   \n",
       "4  9.427983e-07  3.519585e-07 -9.359679e-07 -0.000002 -1.133617e-06  ...   \n",
       "\n",
       "    px_1591   px_1592   px_1593   px_1594   px_1595       px_1596   px_1597  \\\n",
       "0 -0.000005 -0.000004 -0.000003 -0.000002 -0.000001 -9.692004e-07 -0.000002   \n",
       "1 -0.000004 -0.000005 -0.000004 -0.000004 -0.000004 -2.549684e-06 -0.000001   \n",
       "2 -0.000007 -0.000006 -0.000005 -0.000005 -0.000005 -4.840686e-06 -0.000003   \n",
       "3 -0.000006 -0.000006 -0.000006 -0.000006 -0.000005 -3.182040e-06 -0.000002   \n",
       "4  1.691117  2.034608  1.726876  1.293826  1.495271  2.457459e+00  3.490596   \n",
       "\n",
       "    px_1598   px_1599   px_1600  \n",
       "0  0.000030  0.000009 -0.000027  \n",
       "1  0.000037  0.000008 -0.000029  \n",
       "2  0.000042 -0.000001 -0.000044  \n",
       "3  0.000034  0.000012 -0.000028  \n",
       "4  3.771606  3.020589  1.592311  \n",
       "\n",
       "[5 rows x 1601 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('../D_WEATHER/sub/unet_ch9_shuffle_trainall_sgd.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sub = sub.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1600/1600 [00:01<00:00, 1336.26it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm.tqdm(range(1,1601)):\n",
    "    new_sub.loc[new_sub[new_sub.columns[i]]<0, new_sub.columns[i]] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>px_1</th>\n",
       "      <th>px_2</th>\n",
       "      <th>px_3</th>\n",
       "      <th>px_4</th>\n",
       "      <th>px_5</th>\n",
       "      <th>px_6</th>\n",
       "      <th>px_7</th>\n",
       "      <th>px_8</th>\n",
       "      <th>px_9</th>\n",
       "      <th>px_10</th>\n",
       "      <th>...</th>\n",
       "      <th>px_1591</th>\n",
       "      <th>px_1592</th>\n",
       "      <th>px_1593</th>\n",
       "      <th>px_1594</th>\n",
       "      <th>px_1595</th>\n",
       "      <th>px_1596</th>\n",
       "      <th>px_1597</th>\n",
       "      <th>px_1598</th>\n",
       "      <th>px_1599</th>\n",
       "      <th>px_1600</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.416000e+03</td>\n",
       "      <td>2.416000e+03</td>\n",
       "      <td>2.416000e+03</td>\n",
       "      <td>2416.000000</td>\n",
       "      <td>2416.000000</td>\n",
       "      <td>2.416000e+03</td>\n",
       "      <td>2.416000e+03</td>\n",
       "      <td>2.416000e+03</td>\n",
       "      <td>2.416000e+03</td>\n",
       "      <td>2.416000e+03</td>\n",
       "      <td>...</td>\n",
       "      <td>2.416000e+03</td>\n",
       "      <td>2.416000e+03</td>\n",
       "      <td>2.416000e+03</td>\n",
       "      <td>2.416000e+03</td>\n",
       "      <td>2.416000e+03</td>\n",
       "      <td>2.416000e+03</td>\n",
       "      <td>2416.000000</td>\n",
       "      <td>2416.000000</td>\n",
       "      <td>2416.000000</td>\n",
       "      <td>2416.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.559341e-02</td>\n",
       "      <td>8.875949e-02</td>\n",
       "      <td>9.809333e-02</td>\n",
       "      <td>0.107009</td>\n",
       "      <td>0.112840</td>\n",
       "      <td>1.116722e-01</td>\n",
       "      <td>1.072851e-01</td>\n",
       "      <td>1.036032e-01</td>\n",
       "      <td>1.004457e-01</td>\n",
       "      <td>9.757449e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>1.015955e-01</td>\n",
       "      <td>9.986147e-02</td>\n",
       "      <td>9.565565e-02</td>\n",
       "      <td>8.982704e-02</td>\n",
       "      <td>8.504089e-02</td>\n",
       "      <td>8.358944e-02</td>\n",
       "      <td>0.084432</td>\n",
       "      <td>0.088947</td>\n",
       "      <td>0.087128</td>\n",
       "      <td>0.057302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.104650e-01</td>\n",
       "      <td>5.024365e-01</td>\n",
       "      <td>5.661610e-01</td>\n",
       "      <td>0.607298</td>\n",
       "      <td>0.627617</td>\n",
       "      <td>6.153193e-01</td>\n",
       "      <td>5.870121e-01</td>\n",
       "      <td>5.722030e-01</td>\n",
       "      <td>5.694665e-01</td>\n",
       "      <td>5.549266e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>5.036964e-01</td>\n",
       "      <td>4.871227e-01</td>\n",
       "      <td>4.753048e-01</td>\n",
       "      <td>4.594024e-01</td>\n",
       "      <td>4.432956e-01</td>\n",
       "      <td>4.419767e-01</td>\n",
       "      <td>0.448452</td>\n",
       "      <td>0.456458</td>\n",
       "      <td>0.425732</td>\n",
       "      <td>0.272556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.643382e-03</td>\n",
       "      <td>-4.434580e-03</td>\n",
       "      <td>-4.922745e-03</td>\n",
       "      <td>-0.007161</td>\n",
       "      <td>-0.005236</td>\n",
       "      <td>-7.377530e-03</td>\n",
       "      <td>-1.017762e-02</td>\n",
       "      <td>-6.293891e-03</td>\n",
       "      <td>-8.222144e-03</td>\n",
       "      <td>-6.106488e-03</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.168703e-03</td>\n",
       "      <td>-8.157551e-03</td>\n",
       "      <td>-1.203220e-02</td>\n",
       "      <td>-1.532285e-02</td>\n",
       "      <td>-1.106421e-02</td>\n",
       "      <td>-1.594329e-02</td>\n",
       "      <td>-0.017979</td>\n",
       "      <td>-0.014005</td>\n",
       "      <td>-0.005273</td>\n",
       "      <td>-0.003900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-9.456120e-07</td>\n",
       "      <td>-3.403284e-07</td>\n",
       "      <td>-5.035908e-06</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-8.228396e-07</td>\n",
       "      <td>-8.551439e-07</td>\n",
       "      <td>-8.390618e-07</td>\n",
       "      <td>-6.641594e-07</td>\n",
       "      <td>-7.745552e-07</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.857403e-06</td>\n",
       "      <td>-4.747880e-06</td>\n",
       "      <td>-4.624227e-06</td>\n",
       "      <td>-4.688958e-06</td>\n",
       "      <td>-4.701681e-06</td>\n",
       "      <td>-3.941757e-06</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.906165e-06</td>\n",
       "      <td>4.838827e-06</td>\n",
       "      <td>-1.578589e-07</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>5.170190e-06</td>\n",
       "      <td>5.070242e-06</td>\n",
       "      <td>5.093080e-06</td>\n",
       "      <td>5.118470e-06</td>\n",
       "      <td>5.319169e-06</td>\n",
       "      <td>...</td>\n",
       "      <td>3.355035e-08</td>\n",
       "      <td>1.797968e-07</td>\n",
       "      <td>2.258598e-07</td>\n",
       "      <td>1.017508e-07</td>\n",
       "      <td>1.975250e-07</td>\n",
       "      <td>6.587668e-07</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>-0.000027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.104125e-06</td>\n",
       "      <td>7.994816e-06</td>\n",
       "      <td>5.492681e-06</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>1.102107e-05</td>\n",
       "      <td>1.092714e-05</td>\n",
       "      <td>1.104188e-05</td>\n",
       "      <td>1.111188e-05</td>\n",
       "      <td>1.126517e-05</td>\n",
       "      <td>...</td>\n",
       "      <td>4.396179e-06</td>\n",
       "      <td>4.536681e-06</td>\n",
       "      <td>4.534815e-06</td>\n",
       "      <td>4.563564e-06</td>\n",
       "      <td>4.458083e-06</td>\n",
       "      <td>4.575743e-06</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>-0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.710314e+00</td>\n",
       "      <td>6.214237e+00</td>\n",
       "      <td>7.453029e+00</td>\n",
       "      <td>9.106943</td>\n",
       "      <td>8.183431</td>\n",
       "      <td>8.330743e+00</td>\n",
       "      <td>8.737432e+00</td>\n",
       "      <td>9.534902e+00</td>\n",
       "      <td>9.696298e+00</td>\n",
       "      <td>1.010775e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>7.304361e+00</td>\n",
       "      <td>6.386330e+00</td>\n",
       "      <td>5.869792e+00</td>\n",
       "      <td>6.304834e+00</td>\n",
       "      <td>7.088170e+00</td>\n",
       "      <td>7.578837e+00</td>\n",
       "      <td>7.628572</td>\n",
       "      <td>7.200710</td>\n",
       "      <td>5.871171</td>\n",
       "      <td>3.314133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 1600 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               px_1          px_2          px_3         px_4         px_5  \\\n",
       "count  2.416000e+03  2.416000e+03  2.416000e+03  2416.000000  2416.000000   \n",
       "mean   5.559341e-02  8.875949e-02  9.809333e-02     0.107009     0.112840   \n",
       "std    3.104650e-01  5.024365e-01  5.661610e-01     0.607298     0.627617   \n",
       "min   -1.643382e-03 -4.434580e-03 -4.922745e-03    -0.007161    -0.005236   \n",
       "25%   -9.456120e-07 -3.403284e-07 -5.035908e-06    -0.000002    -0.000002   \n",
       "50%    2.906165e-06  4.838827e-06 -1.578589e-07     0.000003     0.000005   \n",
       "75%    5.104125e-06  7.994816e-06  5.492681e-06     0.000008     0.000012   \n",
       "max    3.710314e+00  6.214237e+00  7.453029e+00     9.106943     8.183431   \n",
       "\n",
       "               px_6          px_7          px_8          px_9         px_10  \\\n",
       "count  2.416000e+03  2.416000e+03  2.416000e+03  2.416000e+03  2.416000e+03   \n",
       "mean   1.116722e-01  1.072851e-01  1.036032e-01  1.004457e-01  9.757449e-02   \n",
       "std    6.153193e-01  5.870121e-01  5.722030e-01  5.694665e-01  5.549266e-01   \n",
       "min   -7.377530e-03 -1.017762e-02 -6.293891e-03 -8.222144e-03 -6.106488e-03   \n",
       "25%   -8.228396e-07 -8.551439e-07 -8.390618e-07 -6.641594e-07 -7.745552e-07   \n",
       "50%    5.170190e-06  5.070242e-06  5.093080e-06  5.118470e-06  5.319169e-06   \n",
       "75%    1.102107e-05  1.092714e-05  1.104188e-05  1.111188e-05  1.126517e-05   \n",
       "max    8.330743e+00  8.737432e+00  9.534902e+00  9.696298e+00  1.010775e+01   \n",
       "\n",
       "       ...       px_1591       px_1592       px_1593       px_1594  \\\n",
       "count  ...  2.416000e+03  2.416000e+03  2.416000e+03  2.416000e+03   \n",
       "mean   ...  1.015955e-01  9.986147e-02  9.565565e-02  8.982704e-02   \n",
       "std    ...  5.036964e-01  4.871227e-01  4.753048e-01  4.594024e-01   \n",
       "min    ... -8.168703e-03 -8.157551e-03 -1.203220e-02 -1.532285e-02   \n",
       "25%    ... -4.857403e-06 -4.747880e-06 -4.624227e-06 -4.688958e-06   \n",
       "50%    ...  3.355035e-08  1.797968e-07  2.258598e-07  1.017508e-07   \n",
       "75%    ...  4.396179e-06  4.536681e-06  4.534815e-06  4.563564e-06   \n",
       "max    ...  7.304361e+00  6.386330e+00  5.869792e+00  6.304834e+00   \n",
       "\n",
       "            px_1595       px_1596      px_1597      px_1598      px_1599  \\\n",
       "count  2.416000e+03  2.416000e+03  2416.000000  2416.000000  2416.000000   \n",
       "mean   8.504089e-02  8.358944e-02     0.084432     0.088947     0.087128   \n",
       "std    4.432956e-01  4.419767e-01     0.448452     0.456458     0.425732   \n",
       "min   -1.106421e-02 -1.594329e-02    -0.017979    -0.014005    -0.005273   \n",
       "25%   -4.701681e-06 -3.941757e-06    -0.000006     0.000027    -0.000005   \n",
       "50%    1.975250e-07  6.587668e-07    -0.000002     0.000034     0.000009   \n",
       "75%    4.458083e-06  4.575743e-06     0.000003     0.000038     0.000022   \n",
       "max    7.088170e+00  7.578837e+00     7.628572     7.200710     5.871171   \n",
       "\n",
       "           px_1600  \n",
       "count  2416.000000  \n",
       "mean      0.057302  \n",
       "std       0.272556  \n",
       "min      -0.003900  \n",
       "25%      -0.000036  \n",
       "50%      -0.000027  \n",
       "75%      -0.000014  \n",
       "max       3.314133  \n",
       "\n",
       "[8 rows x 1600 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>px_1</th>\n",
       "      <th>px_2</th>\n",
       "      <th>px_3</th>\n",
       "      <th>px_4</th>\n",
       "      <th>px_5</th>\n",
       "      <th>px_6</th>\n",
       "      <th>px_7</th>\n",
       "      <th>px_8</th>\n",
       "      <th>px_9</th>\n",
       "      <th>px_10</th>\n",
       "      <th>...</th>\n",
       "      <th>px_1591</th>\n",
       "      <th>px_1592</th>\n",
       "      <th>px_1593</th>\n",
       "      <th>px_1594</th>\n",
       "      <th>px_1595</th>\n",
       "      <th>px_1596</th>\n",
       "      <th>px_1597</th>\n",
       "      <th>px_1598</th>\n",
       "      <th>px_1599</th>\n",
       "      <th>px_1600</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2416.000000</td>\n",
       "      <td>2416.000000</td>\n",
       "      <td>2416.000000</td>\n",
       "      <td>2416.000000</td>\n",
       "      <td>2416.000000</td>\n",
       "      <td>2416.000000</td>\n",
       "      <td>2416.000000</td>\n",
       "      <td>2416.000000</td>\n",
       "      <td>2416.000000</td>\n",
       "      <td>2416.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.416000e+03</td>\n",
       "      <td>2.416000e+03</td>\n",
       "      <td>2.416000e+03</td>\n",
       "      <td>2.416000e+03</td>\n",
       "      <td>2.416000e+03</td>\n",
       "      <td>2.416000e+03</td>\n",
       "      <td>2416.000000</td>\n",
       "      <td>2416.000000</td>\n",
       "      <td>2416.000000</td>\n",
       "      <td>2416.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.055601</td>\n",
       "      <td>0.088781</td>\n",
       "      <td>0.098126</td>\n",
       "      <td>0.107047</td>\n",
       "      <td>0.112870</td>\n",
       "      <td>0.111705</td>\n",
       "      <td>0.107324</td>\n",
       "      <td>0.103639</td>\n",
       "      <td>0.100494</td>\n",
       "      <td>0.097617</td>\n",
       "      <td>...</td>\n",
       "      <td>1.016247e-01</td>\n",
       "      <td>9.988687e-02</td>\n",
       "      <td>9.568436e-02</td>\n",
       "      <td>8.986553e-02</td>\n",
       "      <td>8.508066e-02</td>\n",
       "      <td>8.363517e-02</td>\n",
       "      <td>0.084490</td>\n",
       "      <td>0.088991</td>\n",
       "      <td>0.087169</td>\n",
       "      <td>0.057344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.310464</td>\n",
       "      <td>0.502433</td>\n",
       "      <td>0.566155</td>\n",
       "      <td>0.607292</td>\n",
       "      <td>0.627612</td>\n",
       "      <td>0.615313</td>\n",
       "      <td>0.587005</td>\n",
       "      <td>0.572196</td>\n",
       "      <td>0.569458</td>\n",
       "      <td>0.554919</td>\n",
       "      <td>...</td>\n",
       "      <td>5.036904e-01</td>\n",
       "      <td>4.871174e-01</td>\n",
       "      <td>4.752989e-01</td>\n",
       "      <td>4.593947e-01</td>\n",
       "      <td>4.432878e-01</td>\n",
       "      <td>4.419678e-01</td>\n",
       "      <td>0.448440</td>\n",
       "      <td>0.456449</td>\n",
       "      <td>0.425724</td>\n",
       "      <td>0.272547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>...</td>\n",
       "      <td>3.355035e-08</td>\n",
       "      <td>1.797968e-07</td>\n",
       "      <td>2.258598e-07</td>\n",
       "      <td>1.017508e-07</td>\n",
       "      <td>1.975250e-07</td>\n",
       "      <td>6.587668e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>...</td>\n",
       "      <td>4.396179e-06</td>\n",
       "      <td>4.536681e-06</td>\n",
       "      <td>4.534815e-06</td>\n",
       "      <td>4.563564e-06</td>\n",
       "      <td>4.458083e-06</td>\n",
       "      <td>4.575743e-06</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.710314</td>\n",
       "      <td>6.214237</td>\n",
       "      <td>7.453029</td>\n",
       "      <td>9.106943</td>\n",
       "      <td>8.183431</td>\n",
       "      <td>8.330743</td>\n",
       "      <td>8.737432</td>\n",
       "      <td>9.534902</td>\n",
       "      <td>9.696298</td>\n",
       "      <td>10.107747</td>\n",
       "      <td>...</td>\n",
       "      <td>7.304361e+00</td>\n",
       "      <td>6.386330e+00</td>\n",
       "      <td>5.869792e+00</td>\n",
       "      <td>6.304834e+00</td>\n",
       "      <td>7.088170e+00</td>\n",
       "      <td>7.578837e+00</td>\n",
       "      <td>7.628572</td>\n",
       "      <td>7.200710</td>\n",
       "      <td>5.871171</td>\n",
       "      <td>3.314133</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 1600 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              px_1         px_2         px_3         px_4         px_5  \\\n",
       "count  2416.000000  2416.000000  2416.000000  2416.000000  2416.000000   \n",
       "mean      0.055601     0.088781     0.098126     0.107047     0.112870   \n",
       "std       0.310464     0.502433     0.566155     0.607292     0.627612   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000003     0.000005     0.000000     0.000003     0.000005   \n",
       "75%       0.000005     0.000008     0.000005     0.000008     0.000012   \n",
       "max       3.710314     6.214237     7.453029     9.106943     8.183431   \n",
       "\n",
       "              px_6         px_7         px_8         px_9        px_10  ...  \\\n",
       "count  2416.000000  2416.000000  2416.000000  2416.000000  2416.000000  ...   \n",
       "mean      0.111705     0.107324     0.103639     0.100494     0.097617  ...   \n",
       "std       0.615313     0.587005     0.572196     0.569458     0.554919  ...   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "50%       0.000005     0.000005     0.000005     0.000005     0.000005  ...   \n",
       "75%       0.000011     0.000011     0.000011     0.000011     0.000011  ...   \n",
       "max       8.330743     8.737432     9.534902     9.696298    10.107747  ...   \n",
       "\n",
       "            px_1591       px_1592       px_1593       px_1594       px_1595  \\\n",
       "count  2.416000e+03  2.416000e+03  2.416000e+03  2.416000e+03  2.416000e+03   \n",
       "mean   1.016247e-01  9.988687e-02  9.568436e-02  8.986553e-02  8.508066e-02   \n",
       "std    5.036904e-01  4.871174e-01  4.752989e-01  4.593947e-01  4.432878e-01   \n",
       "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "25%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "50%    3.355035e-08  1.797968e-07  2.258598e-07  1.017508e-07  1.975250e-07   \n",
       "75%    4.396179e-06  4.536681e-06  4.534815e-06  4.563564e-06  4.458083e-06   \n",
       "max    7.304361e+00  6.386330e+00  5.869792e+00  6.304834e+00  7.088170e+00   \n",
       "\n",
       "            px_1596      px_1597      px_1598      px_1599      px_1600  \n",
       "count  2.416000e+03  2416.000000  2416.000000  2416.000000  2416.000000  \n",
       "mean   8.363517e-02     0.084490     0.088991     0.087169     0.057344  \n",
       "std    4.419678e-01     0.448440     0.456449     0.425724     0.272547  \n",
       "min    0.000000e+00     0.000000     0.000000     0.000000     0.000000  \n",
       "25%    0.000000e+00     0.000000     0.000027     0.000000     0.000000  \n",
       "50%    6.587668e-07     0.000000     0.000034     0.000009     0.000000  \n",
       "75%    4.575743e-06     0.000003     0.000038     0.000022     0.000000  \n",
       "max    7.578837e+00     7.628572     7.200710     5.871171     3.314133  \n",
       "\n",
       "[8 rows x 1600 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_sub.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>px_1</th>\n",
       "      <th>px_2</th>\n",
       "      <th>px_3</th>\n",
       "      <th>px_4</th>\n",
       "      <th>px_5</th>\n",
       "      <th>px_6</th>\n",
       "      <th>px_7</th>\n",
       "      <th>px_8</th>\n",
       "      <th>px_9</th>\n",
       "      <th>...</th>\n",
       "      <th>px_1591</th>\n",
       "      <th>px_1592</th>\n",
       "      <th>px_1593</th>\n",
       "      <th>px_1594</th>\n",
       "      <th>px_1595</th>\n",
       "      <th>px_1596</th>\n",
       "      <th>px_1597</th>\n",
       "      <th>px_1598</th>\n",
       "      <th>px_1599</th>\n",
       "      <th>px_1600</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>029858_01</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.971598e-03</td>\n",
       "      <td>1.805135e-02</td>\n",
       "      <td>0.020831</td>\n",
       "      <td>0.012910</td>\n",
       "      <td>0.001236</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>029858_02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.230757e-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>029858_03</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.005665e-03</td>\n",
       "      <td>1.169641e-05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>029858_05</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.777665e-08</td>\n",
       "      <td>3.525572e-06</td>\n",
       "      <td>4.301689e-06</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>029858_07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.675309e-06</td>\n",
       "      <td>9.427983e-07</td>\n",
       "      <td>3.519585e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.691117</td>\n",
       "      <td>2.034608</td>\n",
       "      <td>1.726876</td>\n",
       "      <td>1.293826</td>\n",
       "      <td>1.495271</td>\n",
       "      <td>2.457459</td>\n",
       "      <td>3.490596</td>\n",
       "      <td>3.771606</td>\n",
       "      <td>3.020589</td>\n",
       "      <td>1.592311</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1601 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id      px_1      px_2  px_3          px_4          px_5  \\\n",
       "0  029858_01  0.000142  0.000000   0.0  0.000000e+00  2.971598e-03   \n",
       "1  029858_02  0.000000  0.000004   0.0  0.000000e+00  0.000000e+00   \n",
       "2  029858_03  0.000003  0.000004   0.0  1.005665e-03  1.169641e-05   \n",
       "3  029858_05  0.000004  0.000006   0.0  2.777665e-08  3.525572e-06   \n",
       "4  029858_07  0.000000  0.000000   0.0  2.675309e-06  9.427983e-07   \n",
       "\n",
       "           px_6      px_7      px_8      px_9  ...   px_1591   px_1592  \\\n",
       "0  1.805135e-02  0.020831  0.012910  0.001236  ...  0.000000  0.000000   \n",
       "1  1.230757e-06  0.000000  0.000000  0.000000  ...  0.000000  0.000000   \n",
       "2  0.000000e+00  0.000000  0.000014  0.000000  ...  0.000000  0.000000   \n",
       "3  4.301689e-06  0.000006  0.000005  0.000003  ...  0.000000  0.000000   \n",
       "4  3.519585e-07  0.000000  0.000000  0.000000  ...  1.691117  2.034608   \n",
       "\n",
       "    px_1593   px_1594   px_1595   px_1596   px_1597   px_1598   px_1599  \\\n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000030  0.000009   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000037  0.000008   \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000042  0.000000   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.000034  0.000012   \n",
       "4  1.726876  1.293826  1.495271  2.457459  3.490596  3.771606  3.020589   \n",
       "\n",
       "    px_1600  \n",
       "0  0.000000  \n",
       "1  0.000000  \n",
       "2  0.000000  \n",
       "3  0.000000  \n",
       "4  1.592311  \n",
       "\n",
       "[5 rows x 1601 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sub.to_csv('../D_WEATHER/sub/unet_ch9_shuffle_trainall_sgd_postpro.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.5 64-bit ('pytorch': conda)",
   "language": "python",
   "name": "python37564bitpytorchconda133dde54c45c40c2946593d30b593426"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
